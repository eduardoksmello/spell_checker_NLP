{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eksm - nlp - spell checker",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqHxaDfoCTw4"
      },
      "source": [
        "# Resumo\n",
        "Este projeto é dedicado à criação de um corretor ortográfico para palavras da língua portuguesa brasileira. O script utilizado foi inspirado no apresentado durante o curso \"Corretor Ortográfico em Python: Aplicando técnicas de NLP\" que frequentei na plataforma Alura.\n",
        "\n",
        "# Base de Dados\n",
        "Uma pequena parte do conjunto de palavras reunido pelo Núcleo Interinstitucional de Linguística Computacional da Universidade de São Paulo (NILC/USP) será utilizado como corpus textual para o corretor ortográfico. A compilação foi realizada para representar o léxico português mais ouvido por crianças e foram utilizadas 5 milhões de arquivos de legendas de filmes e séries dos gêneros Família e Animação do site Open Subtitle.\n",
        "\n",
        "**Disponível em:** http://www.nilc.icmc.usp.br/leg2kids/\n",
        "\n",
        "**Arquivo utilizado:** 'Legendas pré-processadas'. \n",
        "\n",
        "Legendas extraídas de seu formato original e processadas com o intuito de remover as marcações de tempo, remover os travessões que indicam fala e remover marketing, comumente encontrando em legendas produzidas por terceiros. Cada legenda está salva em um arquivo único. Cada trecho de fala da legenda está em uma linha do arquivo. Todos os arquivos possuem codificação utf-8. Conteúdo limpo e \"cru\", indicado para propósitos gerais. Conteúdo em formato zip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qul2wmwgXXR"
      },
      "source": [
        "# Importando o Corpus Textual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLppeGgHdZyD",
        "outputId": "75c938f5-8803-4368-d9f8-0c9869fa1c9b"
      },
      "source": [
        "# acessando arquivo de texto via url do dropbox\n",
        "url = 'https://www.dropbox.com/s/ufyw476gan5sr6j/corpus_raw.txt?dl=1'\n",
        "import urllib.request\n",
        "\n",
        "u = urllib.request.urlopen(url)\n",
        "data = u.read()\n",
        "u.close()\n",
        "\n",
        "with open('corpus_palavras.txt', 'wb') as f :\n",
        "     f.write(data)\n",
        "\n",
        "# lendo o arquivo\n",
        "with open(\"corpus_palavras.txt\", \"r\") as f:\n",
        "     corpus = f.read()\n",
        "  \n",
        "print(corpus[:200])"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ^ MINHA BELA DAMA\n",
            " ^ Freddy, vá chamar um táxi.\n",
            " ^ Você quer que eu pegue uma pneumonia?\n",
            " ^ Não fique aí parado.\n",
            " ^ Chame um táxi.\n",
            " ^ Está bem, vou chamar.\n",
            " ^ Olhe por onde anda,\n",
            " ^ Olhe por onde and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0yilt9Vi2Go"
      },
      "source": [
        "# Avaliando o Corpus Textual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnawNsNmLmf4"
      },
      "source": [
        "Processo elencados:\n",
        "* Tokenização - \n",
        "* Normalização - \n",
        "* Contagemn de palavras -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucK9OAZYjIDQ"
      },
      "source": [
        "## Tokenização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SO5b6C2Inry"
      },
      "source": [
        "Uma tentativa de tokenização poderia ser realizada com o método split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bu2wHH4IxEv"
      },
      "source": [
        "tokens_split = corpus.split()"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pLYq7LLhUFH",
        "outputId": "90a28168-950a-4aa2-8963-e3693c60aba9"
      },
      "source": [
        "print(f'Com o método split teríamos {len(corpus.split())} tokens.')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Com o método split teríamos 661079 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcNqvlB001Ow"
      },
      "source": [
        "Tokens estão separados, todavia, elementos de pontuação aparecem junto com as palavras. Como o token abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o7tBPA29Kd_x",
        "outputId": "e5d8930d-0a39-4d09-af9c-d3a285188b0a"
      },
      "source": [
        "tokens_split[5]"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Freddy,'"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOu59uFMKiOf"
      },
      "source": [
        "Para resolver esse problema, será utilizada a bibliteca 'Natural Language Toolkit' no processo de tokenização."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV2hlmtf1Kdw",
        "outputId": "49c0b5fb-db0e-4834-ab87-88d514ca13b5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31G8IvAST9Cg"
      },
      "source": [
        "Aplicando o método 'word_tokenize' no corpus textual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B87nNvTJQ8OA",
        "outputId": "daa43e9f-8a80-44f7-e7b4-1c71faddc3f0"
      },
      "source": [
        "tokens = nltk.tokenize.word_tokenize(corpus)\n",
        "tokens[:10]"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['^', 'MINHA', 'BELA', 'DAMA', '^', 'Freddy', ',', 'vá', 'chamar', 'um']"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkv0urs1RbVf"
      },
      "source": [
        "O método resultou na tokenização de palavras, mas ainda apresenta os caracteres de pontuação como tokens.\n",
        "\n",
        "Para refinar a contagem de palavras do corpus será criada a função 'separa_apenas_palavras'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RREXuxTI20LZ"
      },
      "source": [
        "def separa_apenas_palavras(lista_tokens):\n",
        "    lista_palavras = []\n",
        "    for token in lista_tokens:\n",
        "        if token.isalpha():\n",
        "           lista_palavras.append(token)\n",
        "    return lista_palavras"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wLw4YfAVtD4"
      },
      "source": [
        "Aplicando a função 'separa_apenas_palavra'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf8gpT1j32Wq",
        "outputId": "59e3536b-513e-43e9-83d9-2b7b9f449ea4"
      },
      "source": [
        "corpus_palavras = separa_apenas_palavras(tokens)\n",
        "\n",
        "# visualização das 10 primeiras palavras do corpus tratado\n",
        "corpus_palavras[:10]"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MINHA',\n",
              " 'BELA',\n",
              " 'DAMA',\n",
              " 'Freddy',\n",
              " 'vá',\n",
              " 'chamar',\n",
              " 'um',\n",
              " 'táxi',\n",
              " 'Você',\n",
              " 'quer']"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75kx0O6Z47z3"
      },
      "source": [
        "Após sucesso da tokenização, será calculado o total de palavras do corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgMuu6M138Rr",
        "outputId": "a3d0168d-5a81-4fc4-be54-ceafbd3e125f"
      },
      "source": [
        "print(f'O número total de palavras do corpus é {len(corpus_palavras)}.')"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número total de palavras do corpus é 525378.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2diyxe53XDmg"
      },
      "source": [
        "## Contagem de Palavras do Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzT3wtdS6KeQ"
      },
      "source": [
        "Para descobrir quantas palavras distintas possuímos no corpus serão realizados: \n",
        "* Normalização do texto - aplicar uma transformação para que palavras iguais sejam reconhecidas da mesma forma, não importando se foram utilizadas letras em caixa alta.\n",
        "* Removeção de palavras repetidas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIoQwepy6MPo"
      },
      "source": [
        "## Normalização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEB7bqJC77qP"
      },
      "source": [
        "Como é possível observer no exemplo abaixo, a lista atual não transforma o texto e armazena palavras com letras maíuscula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfsTPV9Q4zH6",
        "outputId": "2cb6abde-385d-46ff-8c8f-f01af259c277"
      },
      "source": [
        "print(corpus_palavras[:5])"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MINHA', 'BELA', 'DAMA', 'Freddy', 'vá']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhpM7GLr7kOQ"
      },
      "source": [
        "Portanto, uma função chamada 'normalizacao' será criada visando a normalização de todas as palavras de um corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVDpN0lw6Gju"
      },
      "source": [
        "def normalizacao(lista_palavras):\n",
        "    lista_normalizada = []\n",
        "    for palavra in lista_palavras:\n",
        "        lista_normalizada.append(palavra.lower())\n",
        "    return lista_normalizada"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIgpSweT9SdX"
      },
      "source": [
        "Assim, a normalização da variável 'corpus_palavras' será realizada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf-oA5ub7h25",
        "outputId": "24a71c1a-c681-404c-9558-d13d97c39475"
      },
      "source": [
        "corpus_normalizado = normalizacao(corpus_palavras)\n",
        "\n",
        "print(corpus_normalizado[:10])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['minha', 'bela', 'dama', 'freddy', 'vá', 'chamar', 'um', 'táxi', 'você', 'quer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_qJ_NET-RMn"
      },
      "source": [
        "# Contagem de palavras não repetidas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rAfGlKb9zzn"
      },
      "source": [
        "Para remover das palavras repetidas da contagem do corpus será utilizada a ferramenta de implementação de conjuntos em python (**set**). Desta forma, será evidenciado a quantidade de palavras que o corretor ortográfico aqui construído saberá corrigir. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woMbsKpEdm2_",
        "outputId": "540b62ab-f3e8-4a42-94b2-4e57a207f049"
      },
      "source": [
        "corpus_sem_repeticao = set(corpus_normalizado)\n",
        "palavras_repetidas = len(corpus_normalizado) - len(corpus_sem_repeticao)\n",
        "\n",
        "print(f'O corpus tem o total de {len(corpus_normalizado)} palavras.')\n",
        "print(f'O corpus possui {palavras_repetidas} palavras repetidas.')\n",
        "print(f'O corretor saberá corrigir {len(corpus_sem_repeticao)} palavras.')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O corpus tem o total de 525378 palavras.\n",
            "O corpus possui 499747 palavras repetidas.\n",
            "O corretor saberá corrigir 25631 palavras.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA_gjMkidOUU"
      },
      "source": [
        "# Criando função de correção mediante a adição de uma letra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFC8uOvudUU6"
      },
      "source": [
        "Nesta seção, será criado um algoritmo para a sugestão de correção em palavras digitadas faltando caracteres (ex:. 'lgica').\n",
        "\n",
        "Para esse processo, será necessário um mecanismo fatie a string de input e teste a inserção de diferentes letras em diferentes posições - gerando palavras - para realizar uma sugestão ao usuário. Como no exemplo a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joC_Ow7686Fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd9635e-106a-4726-dd91-8c743c00fb5c"
      },
      "source": [
        "# exemplo de fatiamento de palavra\n",
        "lista = [1, 2, 3]\n",
        "print(f'lista = {lista}')\n",
        "print(lista[0])\n",
        "print(lista[1:2])\n",
        "print(lista[1:3])\n",
        "print()\n",
        "\n",
        "lista = \"lgica\"\n",
        "print(f'lista = {lista}')\n",
        "print(f'1º fatiamento: {(lista[:0], lista[0:])}')\n",
        "print(f'2º fatiamento: {(lista[:1], lista[1:])}')\n",
        "print(f'3º fatiamento: {(lista[:2], lista[2:])}')\n",
        "print(f'4º fatiamento: {(lista[:3], lista[3:])}')\n",
        "print(f'5º fatiamento: {(lista[:4], lista[4:])}')\n",
        "print(f'6º fatiamento: {(lista[:5], lista[5:])}')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lista = [1, 2, 3]\n",
            "1\n",
            "[2]\n",
            "[2, 3]\n",
            "\n",
            "lista = lgica\n",
            "1º fatiamento: ('', 'lgica')\n",
            "2º fatiamento: ('l', 'gica')\n",
            "3º fatiamento: ('lg', 'ica')\n",
            "4º fatiamento: ('lgi', 'ca')\n",
            "5º fatiamento: ('lgic', 'a')\n",
            "6º fatiamento: ('lgica', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRJLJwscdng7"
      },
      "source": [
        "Portanto, no processo de correção aqui desenvolvido, a palavra digitada equivocadamente será fatiada em duas partes de todas as formas demonstradas no exemplo anterior. Em seguida, cada letra do alfabeto (mais letras acentuadas e ç) será posicionada entre as partes fatiadas com o objetivo de formar um escopo de palavras possíveis com a adição de apenas uma letra à palavra digitada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhpEi0KSdotc"
      },
      "source": [
        "# função que insere uma letra entre duas fatias de uma palavra\n",
        "def insere_letras(fatias):\n",
        "    novas_palavras = []\n",
        "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "    for E, D in fatias:\n",
        "        for letra in letras:\n",
        "            novas_palavras.append(E + letra + D)\n",
        "    return novas_palavras\n",
        "\n",
        "# função que retorna possíveis palavras adicionando uma letra na digitação\n",
        "def gerador_palavras(palavra):\n",
        "    fatias = []\n",
        "    for i in range(len(palavra)+1):\n",
        "        fatias.append((palavra[:i], palavra[i:]))\n",
        "    palavras_geradas = insere_letras(fatias)\n",
        "    return palavras_geradas"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScKy_RZHe8fS"
      },
      "source": [
        "Para exemplificar o funcionamento, será observado o comportamento do corretor ao receber a string \"tste\". O primeiro passo é o fatiamento da palavra. Depois o gerador retorna possíveis palavras formadas pela inserção da variável 'letras' (todas as letras do alfabeto, vogais acentuadas e o 'ç') entre as fatias da string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5u0UaZudoqi",
        "outputId": "7c2a0197-2535-45cb-92fd-ffe89c0c1523"
      },
      "source": [
        "palavra_exemplo = 'tste'\n",
        "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
        "print(palavras_geradas)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['atste', 'btste', 'ctste', 'dtste', 'etste', 'ftste', 'gtste', 'htste', 'itste', 'jtste', 'ktste', 'ltste', 'mtste', 'ntste', 'otste', 'ptste', 'qtste', 'rtste', 'stste', 'ttste', 'utste', 'vtste', 'wtste', 'xtste', 'ytste', 'ztste', 'àtste', 'átste', 'âtste', 'ãtste', 'ètste', 'étste', 'êtste', 'ìtste', 'ítste', 'îtste', 'òtste', 'ótste', 'ôtste', 'õtste', 'ùtste', 'útste', 'ûtste', 'çtste', 'taste', 'tbste', 'tcste', 'tdste', 'teste', 'tfste', 'tgste', 'thste', 'tiste', 'tjste', 'tkste', 'tlste', 'tmste', 'tnste', 'toste', 'tpste', 'tqste', 'trste', 'tsste', 'ttste', 'tuste', 'tvste', 'twste', 'txste', 'tyste', 'tzste', 'tàste', 'táste', 'tâste', 'tãste', 'tèste', 'téste', 'têste', 'tìste', 'tíste', 'tîste', 'tòste', 'tóste', 'tôste', 'tõste', 'tùste', 'túste', 'tûste', 'tçste', 'tsate', 'tsbte', 'tscte', 'tsdte', 'tsete', 'tsfte', 'tsgte', 'tshte', 'tsite', 'tsjte', 'tskte', 'tslte', 'tsmte', 'tsnte', 'tsote', 'tspte', 'tsqte', 'tsrte', 'tsste', 'tstte', 'tsute', 'tsvte', 'tswte', 'tsxte', 'tsyte', 'tszte', 'tsàte', 'tsáte', 'tsâte', 'tsãte', 'tsète', 'tséte', 'tsête', 'tsìte', 'tsíte', 'tsîte', 'tsòte', 'tsóte', 'tsôte', 'tsõte', 'tsùte', 'tsúte', 'tsûte', 'tsçte', 'tstae', 'tstbe', 'tstce', 'tstde', 'tstee', 'tstfe', 'tstge', 'tsthe', 'tstie', 'tstje', 'tstke', 'tstle', 'tstme', 'tstne', 'tstoe', 'tstpe', 'tstqe', 'tstre', 'tstse', 'tstte', 'tstue', 'tstve', 'tstwe', 'tstxe', 'tstye', 'tstze', 'tstàe', 'tstáe', 'tstâe', 'tstãe', 'tstèe', 'tstée', 'tstêe', 'tstìe', 'tstíe', 'tstîe', 'tstòe', 'tstóe', 'tstôe', 'tstõe', 'tstùe', 'tstúe', 'tstûe', 'tstçe', 'tstea', 'tsteb', 'tstec', 'tsted', 'tstee', 'tstef', 'tsteg', 'tsteh', 'tstei', 'tstej', 'tstek', 'tstel', 'tstem', 'tsten', 'tsteo', 'tstep', 'tsteq', 'tster', 'tstes', 'tstet', 'tsteu', 'tstev', 'tstew', 'tstex', 'tstey', 'tstez', 'tsteà', 'tsteá', 'tsteâ', 'tsteã', 'tsteè', 'tsteé', 'tsteê', 'tsteì', 'tsteí', 'tsteî', 'tsteò', 'tsteó', 'tsteô', 'tsteõ', 'tsteù', 'tsteú', 'tsteû', 'tsteç']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBL3t0WYhk5M"
      },
      "source": [
        "A aplicação do corretor ocorrerá com a avaliação das palavras geradas (escopo de palavras possíveis). Por fim, a palavra com a maior maior frequência no corpus será retornada como sugestão. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf2GwftVdon6"
      },
      "source": [
        "# função corretor que recebe a palavra errada e sugere a palavra correta\n",
        "def corretor(palavra):\n",
        "    palavras_geradas = gerador_palavras(palavra)\n",
        "    palavra_correta = max(palavras_geradas, key = probabilidade)\n",
        "    return palavra_correta"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após gerar as paravras derivadas da errada, o corretor deverá apresentar a mais provável correção. A escolhida será, entre as derivadas, aquela mais frequente no corpus. Para tal, a função *probabilidade* irá retornar a taxa de *frequencia* de cada sugestão no corpus."
      ],
      "metadata": {
        "id": "OVPLjiJ2nLAP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGmZ1uSfdolK",
        "outputId": "306982a8-b52f-43af-b78a-1efa311d7e85"
      },
      "source": [
        "# número de palavras no corpus\n",
        "total_palavras = len(corpus_normalizado)\n",
        "\n",
        "# frequencia de cada palavra no corpus\n",
        "frequencia = nltk.FreqDist(corpus_normalizado)\n",
        "frequencia.most_common(10)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('que', 17020),\n",
              " ('o', 15103),\n",
              " ('não', 13720),\n",
              " ('de', 12541),\n",
              " ('a', 11908),\n",
              " ('você', 11116),\n",
              " ('é', 10584),\n",
              " ('eu', 9633),\n",
              " ('e', 9383),\n",
              " ('um', 7025)]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnxmQQ-0doEz"
      },
      "source": [
        "# função que define a probabilidade das palavras geradas a ser a correta\n",
        "def probabilidade(palavra_gerada):\n",
        "    return frequencia[palavra_gerada]/total_palavras"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yavtob-I9lNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc70038-8386-4562-96b6-99f34c7267a0"
      },
      "source": [
        "probabilidade(\"de\")"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.023870432336336886"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGJKx6tyi9x9",
        "outputId": "9ac5092b-380f-41fd-ce8d-6b09c0023a50"
      },
      "source": [
        "# exemplos de uso da função com o corpus selecionado\n",
        "print('USO DO CORRETOR COM PALAVRA DIGITADA FALTANDO UMA LETRA')\n",
        "print(f'Input = \"crretor\" -  Sugestão = \"{corretor(\"crretor\")}\"')\n",
        "print(f'Input = \"ága\" -  Sugestão = \"{corretor(\"ága\")}\"')\n",
        "print(f'Input = \"luzs\" -  Sugestão = \"{corretor(\"luzs\")}\"')\n",
        "print(f'Input = \"prbabilidade\" -  Sugestão = \"{corretor(\"prbabilidade\")}\"')\n",
        "print()\n",
        "print('USO DO CORRETOR COM PALAVRA DIGITADA FALTANDO DUAS LETRAS')\n",
        "print(f'Input = \"crrtor\" -  Sugestão = \"{corretor(\"crrtor\")}\"')\n",
        "print(f'Input = \"prbbilidade\" -  Sugestão = \"{corretor(\"prbbilidade\")}\"')\n",
        "print()\n",
        "print('USO DO CORRETOR COM PALAVRA DIGITADA COM LETRAS ERRADAS')\n",
        "print(f'Input = \"corrretor\" -  Sugestão = \"{corretor(\"corrretor\")}\"')\n",
        "print(f'Input = \"probabillidade\" -  Sugestão = \"{corretor(\"probabillidade\")}\"')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USO DO CORRETOR COM PALAVRA DIGITADA FALTANDO UMA LETRA\n",
            "Input = \"crretor\" -  Sugestão = \"corretor\"\n",
            "Input = \"ága\" -  Sugestão = \"água\"\n",
            "Input = \"luzs\" -  Sugestão = \"luzes\"\n",
            "Input = \"prbabilidade\" -  Sugestão = \"probabilidade\"\n",
            "\n",
            "USO DO CORRETOR COM PALAVRA DIGITADA FALTANDO DUAS LETRAS\n",
            "Input = \"crrtor\" -  Sugestão = \"acrrtor\"\n",
            "Input = \"prbbilidade\" -  Sugestão = \"aprbbilidade\"\n",
            "\n",
            "USO DO CORRETOR COM PALAVRA DIGITADA COM LETRAS ERRADAS\n",
            "Input = \"corrretor\" -  Sugestão = \"acorrretor\"\n",
            "Input = \"probabillidade\" -  Sugestão = \"aprobabillidade\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOmrU0pJtBib"
      },
      "source": [
        "O corretor está funcionando perfeitamente. Todavia, apenas para um tipo de erro: quando o usuário esquece alguma das letras da palavra.\n",
        "A seguir, uma função de avaliação do modelo será implementada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_jxAKoDVfO8"
      },
      "source": [
        "# Avaliação do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaF8fbqlViSG"
      },
      "source": [
        "## Carregar base de dados para teste do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVmhsi2GjEnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95951ed-270e-440a-b9a5-a3ab578bb086"
      },
      "source": [
        "url = 'https://www.dropbox.com/s/nxquh7ozkojt7bb/palavras.txt?dl=1'\n",
        "\n",
        "u_2 = urllib.request.urlopen(url)\n",
        "data_2 = u_2.read()\n",
        "u_2.close()\n",
        "\n",
        "with open('palavras.txt', \"wb\") as f :\n",
        "     f.write(data_2)\n",
        "\n",
        "# lendo o arquivo\n",
        "with open(\"palavras.txt\", \"r\") as f:\n",
        "     palavras = f.read()\n",
        "  \n",
        "print(palavras[:55])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "podemos pyodemos\n",
            "esse esje\n",
            "já jrá\n",
            "nosso nossov\n",
            "são sãêo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg7gWmpKYEpE"
      },
      "source": [
        "Nesse momento, a base de dados contempla palavras corretas e palavras com erros ortográficos. Portanto, a próxima função será destinada à divisão destas categorias de palavras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_UBkBHHYBC1"
      },
      "source": [
        "## Criação de função que divide base de dados para testar o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l6xSaxfs_43"
      },
      "source": [
        "def cria_dados_teste(nome_do_arquivo):\n",
        "    lista_palavras_teste = []\n",
        "    f = open(nome_do_arquivo, \"r\")\n",
        "    for linha in f:\n",
        "        correta, errada = linha.split()\n",
        "        lista_palavras_teste.append((correta, errada))\n",
        "    f.close()\n",
        "    return lista_palavras_teste"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBTXnZo2YZPH",
        "outputId": "c5f2a9ff-9113-48b8-f07c-bd2c9969eeb9"
      },
      "source": [
        "# teste da função cria_dados_teste\n",
        "lista_teste = cria_dados_teste(\"palavras.txt\")\n",
        "lista_teste[:5]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('podemos', 'pyodemos'),\n",
              " ('esse', 'esje'),\n",
              " ('já', 'jrá'),\n",
              " ('nosso', 'nossov'),\n",
              " ('são', 'sãêo')]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pYP02OHYnw8"
      },
      "source": [
        "## Criação de função de avaliação do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxRi4MRoYuHd"
      },
      "source": [
        "A função de avaliação será criada com o objetivo de mensurar o funcionamento do corretor. O *avaliador* recebe uma lista de palavras com erros, apresenta sugestões (por meio da função *corretor*) e retorna a média de acertos do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVf6ouu3YZMk"
      },
      "source": [
        "def avaliador(testes):\n",
        "    numero_palavras = len(testes)\n",
        "    acertou = 0\n",
        "    for correta, errada in testes:\n",
        "        palavra_corrigida = corretor(errada)\n",
        "        if palavra_corrigida == correta:\n",
        "          acertou += 1\n",
        "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "    print(f'Sugestões corretas: {taxa_acerto}% de {numero_palavras} palavras.')"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxx29KaMdj1L"
      },
      "source": [
        "Avaliando o estado atual do corretor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THn-T7RSYZKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd799bb4-888f-4547-81c8-435341dac5ac"
      },
      "source": [
        "avaliador(lista_teste)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sugestões corretas: 2.05% de 195 palavras.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDA7nDyd0ew"
      },
      "source": [
        "A seguir, uma função de correção de palavras digitadas com um caracter a mais será criada para melhorar a performance do correto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLmBX7cBYYL7"
      },
      "source": [
        "# Criando função de correção mediante a remoção de uma letra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bauJFUO1ViLk"
      },
      "source": [
        "Para o processo de correção mediante a remoção de uma letra, um mecanismo de fatiamento da string de input, novamente será utilizado. Em seguida, a primeira letra do lado direito será removida. Por fim, as duas partes serão concatenadas e o resultado será sugerido ao usuário.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1SMP0BWeICG",
        "outputId": "590587d1-4c71-42e0-a4b2-1b40cd6b15e6"
      },
      "source": [
        "# exemplo do funcionamento de fatiamento e remoção de caracter\n",
        "lista = \"lóigica\"\n",
        "print(f'lista = {lista}')\n",
        "print(f'1º remoção: {(lista[:0], lista[1:])}')\n",
        "print(f'2º remoção: {(lista[:1], lista[2:])}')\n",
        "print(f'3º remoção: {(lista[:2], lista[3:])}')\n",
        "print(f'4º remoção: {(lista[:3], lista[4:])}')\n",
        "print(f'5º remoção: {(lista[:4], lista[5:])}')\n",
        "print(f'6º remoção: {(lista[:5], lista[6:])}')"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lista = lóigica\n",
            "1º remoção: ('', 'óigica')\n",
            "2º remoção: ('l', 'igica')\n",
            "3º remoção: ('ló', 'gica')\n",
            "4º remoção: ('lói', 'ica')\n",
            "5º remoção: ('lóig', 'ca')\n",
            "6º remoção: ('lóigi', 'a')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glqAQyzPeK1E"
      },
      "source": [
        "Portanto, o segundo processo de correção atende o problema de palavras digitada equivocadamente com um caracter extra. Mais uma vez, o procedimento consiste em fatiar a palavra em duas partes de todas as formas demonstradas no exemplo. Em seguida, será removida a primeira letra da segunda parte de cada forma fatiada, com o objetivo de formar um escopo de palavras sugeridas ao usuário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUaCJUaLeJ3P"
      },
      "source": [
        "def deleta_letras(fatias):\n",
        "    novas_palavras = []\n",
        "    for E, D in fatias:\n",
        "        novas_palavras.append(E + D[1:])\n",
        "    return novas_palavras"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5FzUXwpeW17"
      },
      "source": [
        "Definida a função que realiza sugestão a partir da remoção de letras, ela será incorporada à uma atualização da função que gera palavras (*gerador_palavras*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRreeKa_eVGx"
      },
      "source": [
        "def gerador_palavras(palavra):\n",
        "    fatias = []\n",
        "    for i in range(len(palavra)+1):\n",
        "        fatias.append((palavra[:i], palavra[i:]))\n",
        "    palavras_geradas = insere_letras(fatias)\n",
        "    palavras_geradas += deleta_letras(fatias)\n",
        "    return palavras_geradas"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dYLA-aU8eagA",
        "outputId": "3d1257ab-b713-4227-eec8-63e8a5deb1bd"
      },
      "source": [
        "# exemplo da função que corrige uma palavra com um caracter extra\n",
        "corretor('llíngua')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'língua'"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbgXdFD6egJM"
      },
      "source": [
        "Uma vez implementada a segunda forma de correção, o modelo será avaliado novamente com a função *avaliador*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1Shqw_7ecFB",
        "outputId": "a80e3dae-1467-4492-fc77-f90ade1fec39"
      },
      "source": [
        "avaliador(lista_teste)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sugestões corretas: 41.03% de 195 palavras.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxmlth5GaWAn"
      },
      "source": [
        "# Criando função de correção mediante a troca de uma letra\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXpiykataZme"
      },
      "source": [
        "A função de troca de uma letra atuará para correção dos casos em que o usuário escreve a palavra com uma letra errada. O processo será iniciado novamente com o mecanismo de fatiamento da string. Em seguida, a primeira letra do lado direito será removida e outro caracter será adicionado em seu lugar. Após a inserção de todos os caracteres possíveis em todos os pontos de fatiamento, o corretor avaliará a palavra de maior ocorrência em seu corpus e o resultado será sugerido ao usuário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eraCOjquaWpN"
      },
      "source": [
        "def troca_letras(fatias):\n",
        "    novas_palavras = []\n",
        "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "    for E, D in fatias:\n",
        "        for letra in letras:\n",
        "            novas_palavras.append(E + letra + D[1:])\n",
        "    return novas_palavras"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEQpoKsRdfqF"
      },
      "source": [
        "Atualizando o modelo com a função de troca de letras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CycwpaSydgn1"
      },
      "source": [
        "def gerador_palavras(palavra):\n",
        "    fatias = []\n",
        "    for i in range(len(palavra)+1):\n",
        "        fatias.append((palavra[:i], palavra[i:]))\n",
        "    palavras_geradas = insere_letras(fatias)\n",
        "    palavras_geradas += deleta_letras(fatias)\n",
        "    palavras_geradas += troca_letras(fatias)\n",
        "    return palavras_geradas"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DhIRuNYdreV"
      },
      "source": [
        "Testando a nova função do corretor com uma palavra errada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pBSRWd2_dnEW",
        "outputId": "2f6f6fe5-8dd5-4577-9e7f-be1a3b7a1f02"
      },
      "source": [
        "corretor('langua')"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'língua'"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH_cDb5gd2T1"
      },
      "source": [
        "Nova avaliação do corretor que agora possui três funções (*insere, deleta e troca letras*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoR8PUJ_d3MU",
        "outputId": "b9b7865b-f353-49f5-822d-28450d710f56"
      },
      "source": [
        "avaliador(lista_teste)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sugestões corretas: 73.33% de 195 palavras.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPYTT_LnZXNV"
      },
      "source": [
        "# Criando função de correção mediante a inversão de letras subsequentes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brSskhxtZaIG"
      },
      "source": [
        "A função de troca de uma letra atuará para correção dos casos em que o usuário escreve a palavra invertendo a posição de duas letras. O processo será iniciado novamente com o mecanismo de fatiamento da string. Em seguida, a primeira letra do lado direito será invertida com a segunda. As partes serão concatenadas e geram uma palavra sugerida. Após a realização de todas as inversões possíveis, o corretor avaliará a palavra de maior ocorrência em seu corpus e o resultado será sugerido ao usuário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkNU1ijJZWp2"
      },
      "source": [
        "def inverte_letras(fatias):\n",
        "    novas_palavras = []\n",
        "    for E, D in fatias:\n",
        "      if len(D) > 1:\n",
        "         novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
        "    return novas_palavras"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enXFy4NVZWSf"
      },
      "source": [
        "Atualizando o modelo com a função que inverte letras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLpH4oJQevp0"
      },
      "source": [
        "def gerador_palavras(palavra):\n",
        "    fatias = []\n",
        "    for i in range(len(palavra)+1):\n",
        "        fatias.append((palavra[:i], palavra[i:]))\n",
        "    palavras_geradas = insere_letras(fatias)\n",
        "    palavras_geradas += deleta_letras(fatias)\n",
        "    palavras_geradas += troca_letras(fatias)\n",
        "    palavras_geradas += inverte_letras(fatias)\n",
        "    return palavras_geradas"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD9cpQ89Zo9W"
      },
      "source": [
        "Testando o corretor com uma palavra escrita com letras invertidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BDU7S26_Zo02",
        "outputId": "377fb5fb-a33e-4bfa-f551-b9bfe59e59ff"
      },
      "source": [
        "corretor('lnígua')"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'língua'"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqKEeXKAZohO"
      },
      "source": [
        "Nova avaliação do corretor que agora possui quatro funções (*insere, deleta, troca e inverte letras*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4ZT3aZkZmPl",
        "outputId": "907f7023-724f-48f9-df46-55b19cc2ff87"
      },
      "source": [
        "avaliador(lista_teste)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sugestões corretas: 76.92% de 195 palavras.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_JaW889eMl9"
      },
      "source": [
        "#Erro do corretor e palavras desconhecidas\n",
        "Uma vez que o corretor não possui uma taxa perfeita de acerto, podemos calcular quanto isso se deve às palavras não contempladas pelo corpus utilizado.\n",
        "\n",
        "Portanto, a função avaliador será atualizada com a finalidade de informar a taxa de palavras desconhecidas presentes no corpus de teste. Para isso, a função deverá retornar a proporção de palavras que foram não corrigidas por não possuírem sua versão correta no corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uor3nb2eHF3"
      },
      "source": [
        "vocabulario = set(corpus_normalizado)\n",
        "\n",
        "def avaliador(testes, vocabulario):\n",
        "    numero_palavras = len(testes)\n",
        "    acertou = 0\n",
        "    desconhecida = 0\n",
        "    for correta, errada in testes:\n",
        "        palavra_corrigida = corretor(errada)\n",
        "        if palavra_corrigida == correta:\n",
        "          acertou += 1\n",
        "        else:\n",
        "            desconhecida += (correta not in vocabulario)\n",
        "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "    taxa_desconhecidas = round(desconhecida*100/numero_palavras, 2)\n",
        "    print(f'Sugestões corretas: {taxa_acerto}% de {numero_palavras} palavras.')\n",
        "    print(f'Palavras desconhecidas: {taxa_desconhecidas}%')"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asbbh1qOeSVr",
        "outputId": "cae2b4f0-d92c-46b6-dbd9-4158b26ac945"
      },
      "source": [
        "avaliador(lista_teste, vocabulario)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sugestões corretas: 76.92% de 195 palavras.\n",
            "Palavras desconhecidas: 8.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8ZxTgiGExb1"
      },
      "source": [
        "# Expansão da correção\n",
        "No estado atual, o corretor realiza apenas uma das ações para a correção das palavras (insere, deleta, troca e inverte letras). O próximo passo tem como objetivo que palavras sugeridas sejam geradas a partir da duas ações do corretor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejb7LmQNfIHH"
      },
      "source": [
        "def gerador_expansao(palavras_geradas):\n",
        "    novas_palavras = []\n",
        "    for palavra in palavras_geradas:\n",
        "        novas_palavras += gerador_palavras(palavra)\n",
        "    return novas_palavras"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eISvbT5ZFHV1"
      },
      "source": [
        "Verificando a capacidade de gerar uma palavra correta tendo dois erros de digitação:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi97_NLNE1h2",
        "outputId": "2bfe70ea-5859-4805-e995-525f51ac61ac"
      },
      "source": [
        "# palavra com dois erros\n",
        "palavra = \"llínagua\"\n",
        "\n",
        "# aplicando o corretor com a expansão\n",
        "palavras_expansao = gerador_expansao(gerador_palavras(palavra))\n",
        "\n",
        "# verificando a presença da palavra correta na lista gerada\n",
        "\"língua\" in palavras_expansao"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7mcRJ9BFO7E"
      },
      "source": [
        "A implementação extendida do corretor funcionou perfeitamente, porém é necessário verificar a performance desse modelo. Uma forma de fazer isso é contar o volume de palavras geradas a partir de uma entrada com dois erros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOuAe5uGFMHF",
        "outputId": "0e08031a-7887-406c-8bae-30de215fbea6"
      },
      "source": [
        "len(palavras_expansao)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "691744"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para otimizar a funcionalidade do corretor, será preciso diminuir o número de palavras avaliadas após a geração. Para isso, a função *novo_contador* irá separar entre aquelas geradas, pelo gerador simples e o expandido, as possíveis candidatas à sugestão. "
      ],
      "metadata": {
        "id": "xURXKWvJohcC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n6iNSWtFT1P"
      },
      "source": [
        "def novo_corretor(palavra):\n",
        "    palavras_geradas = gerador_palavras(palavra)\n",
        "    palavras_expansao = gerador_expansao(palavras_geradas)\n",
        "    todas_palavras = set(palavras_geradas + palavras_expansao)\n",
        "    candidatos = [palavra]\n",
        "    for palavra in todas_palavras:\n",
        "        if palavra in vocabulario:\n",
        "           candidatos.append(palavra)\n",
        "    print(len(candidatos))\n",
        "    palavra_correta = max(candidatos, key = probabilidade)\n",
        "    return palavra_correta"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A mesma entrada com dois erros foi submetida ao novo corretor. Nota-se que a quantidade de palavras avaliadas (*candidatos*) é significamente inferior quando comparada àquela gerada pelo processo expandido de correção:"
      ],
      "metadata": {
        "id": "miG8W_p-opsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novo_corretor(palavra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "gSf2THQtom6Y",
        "outputId": "8c589d41-cedd-4c16-dd5f-3d58ded0c6e3"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'língua'"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptação da função avaliador para palavras duas vezes distantes da correta"
      ],
      "metadata": {
        "id": "u9EFqPCZowSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base nas funções *corretor* e *avaliador* serão criadas novas funções para atender a correção de palavras duas vezes distantes da correta."
      ],
      "metadata": {
        "id": "tcKQMFh1ozLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ajuste na função novo_corretor - retirar o print com o número de candidatos\n",
        "def novo_corretor(palavra):\n",
        "    palavras_geradas = gerador_palavras(palavra)\n",
        "    palavras_expansao = gerador_expansao(palavras_geradas)\n",
        "    todas_palavras = set(palavras_geradas + palavras_expansao)\n",
        "    candidatos = [palavra]\n",
        "    for palavra in todas_palavras:\n",
        "        if palavra in vocabulario:\n",
        "           candidatos.append(palavra)\n",
        "    palavra_correta = max(candidatos, key = probabilidade)\n",
        "    return palavra_correta\n",
        "\n",
        "# adaptação da função avaliador - palavras duas vezes distantes\n",
        "def novo_avaliador(testes, vocabulario):\n",
        "    numero_palavras = len(testes)\n",
        "    acertou = 0\n",
        "    desconhecida = 0\n",
        "    for correta, errada in testes:\n",
        "        palavra_corrigida = novo_corretor(errada)\n",
        "        # ajuste - 'desconhecida' deve ter um valor fixo e não variável \n",
        "        desconhecida += (correta not in vocabulario) \n",
        "        if palavra_corrigida == correta:\n",
        "          acertou += 1\n",
        "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "    taxa_desconhecidas = round(desconhecida*100/numero_palavras, 2)\n",
        "    print(f'Sugestões corretas: {taxa_acerto}% de {numero_palavras} palavras.')\n",
        "    print(f'Palavras desconhecidas: {taxa_desconhecidas}%')"
      ],
      "metadata": {
        "id": "NTDrBkZ-osAT"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando o corretor com a função que altera duas vezes a palavra errada:"
      ],
      "metadata": {
        "id": "kh2U0Jy2o4QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novo_avaliador(lista_teste, vocabulario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67QQRueko1pe",
        "outputId": "766c5cdf-1ca3-4862-a4e7-036ab516f454"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sugestões corretas: 41.54% de 195 palavras.\n",
            "Palavras desconhecidas: 8.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para melhor compreensão do resultado gerado pela atualização da função *avaliador*, será realizada uma alteração em seu código. A nova função *analise_avaliador* retorna a concatenação de \"palavra errada - palavra corrigida com o corretor antigo - palavra corrigida com o novo corretor\"."
      ],
      "metadata": {
        "id": "w0fcQ9q0tMlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analise_novo_avaliador(testes, vocabulario):\n",
        "    numero_palavras = len(testes)\n",
        "    acertou = 0\n",
        "    desconhecida = 0\n",
        "    for correta, errada in testes:\n",
        "        palavra_corrigida = novo_corretor(errada)\n",
        "        desconhecida += (correta not in vocabulario) \n",
        "        if palavra_corrigida == correta:\n",
        "          acertou += 1\n",
        "        # análise do resultado (palavra com erro - antigo corretor - novo)\n",
        "        else:\n",
        "          print(errada + \"-\" + corretor(errada) + \"-\" + palavra_corrigida)\n",
        "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "    taxa_desconhecidas = round(desconhecida*100/numero_palavras, 2)\n",
        "    print(f'Sugestões corretas: {taxa_acerto}% de {numero_palavras} palavras.')\n",
        "    print(f'Palavras desconhecidas: {taxa_desconhecidas}%')"
      ],
      "metadata": {
        "id": "7YqIhpNmtJnU"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao executar a função com a *lista_teste*, é possível analisar a performance dos dois corretores criados."
      ],
      "metadata": {
        "id": "Hj3np_3U3-eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analise_novo_avaliador(lista_teste, vocabulario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGLpF_fh38qV",
        "outputId": "756a807e-c058-4814-e43a-79f1983a8cda"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "esje-este-está\n",
            "jrá-já-há\n",
            "nossov-nosso-posso\n",
            "sãêo-são-não\n",
            "dosa-dos-do\n",
            "eme-ele-que\n",
            "temfs-temos-tem\n",
            "eàssa-essa-esta\n",
            "sjava-java-estava\n",
            "daõs-das-mas\n",
            "céda-cada-da\n",
            "noâ-no-o\n",
            "fobma-forma-fora\n",
            "enêão-então-não\n",
            "èriar-criar-tirar\n",
            "cóeigo-código-comigo\n",
            "casío-caso-casa\n",
            "tĩem-tem-em\n",
            "dfados-dados-diabos\n",
            "pgthon-python-pathan\n",
            "nossah-nossa-nosso\n",
            "asõim-assim-sim\n",
            "teb-tem-de\n",
            "atĩ-até-a\n",
            "âem-em-de\n",
            "foo-foi-o\n",
            "empresà-empresa-emprego\n",
            "serr-ser-se\n",
            "entke-entre-então\n",
            "méqodo-método-modo\n",
            "ainàa-ainda-minha\n",
            "van-vai-a\n",
            "ûconteúdo-aûconteúdo-contendo\n",
            "çeus-seus-eu\n",
            "eû-eu-o\n",
            "temeo-tempo-tem\n",
            "semre-sempre-ser\n",
            "elaá-ela-está\n",
            "síó-só-se\n",
            "prhojeto-projeto-prometo\n",
            "siàe-site-se\n",
            "seém-sem-se\n",
            "peln-pelo-ele\n",
            "aléra-aaléra-agora\n",
            "tdia-dia-da\n",
            "eẽsse-esse-disse\n",
            "jé-é-o\n",
            "nçosso-nosso-posso\n",
            "sãô-são-não\n",
            "odos-todos-do\n",
            "siua-sua-seu\n",
            "teos-temos-os\n",
            "eũsa-essa-ela\n",
            "jkva-java-nova\n",
            "dms-dos-de\n",
            "cava-casa-para\n",
            "ános-nos-os\n",
            "forûa-fora-fora\n",
            "criôar-criar-cuidar\n",
            "cóàigo-código-comigo\n",
            "èaso-caso-isso\n",
            "túem-tem-em\n",
            "daáos-dados-vamos\n",
            "nossk-nosso-nos\n",
            "tãer-ter-tem\n",
            "vté-até-é\n",
            "búm-bem-um\n",
            "sçerá-será-ser\n",
            "entró-entre-então\n",
            "nétodo-método-todo\n",
            "uai-vai-a\n",
            "cĩonteúdo-acĩonteúdo-contendo\n",
            "sâus-seus-seu\n",
            "ìeu-eu-que\n",
            "fual-qual-sua\n",
            "elal-ela-ele\n",
            "skó-só-se\n",
            "proójeto-projeto-prometo\n",
            "isite-site-este\n",
            "secm-sem-se\n",
            "aluéa-aluna-alguém\n",
            "dil-dia-de\n",
            "sód-só-se\n",
            "sõêm-asõêm-sim\n",
            "asuraó-aasuraó-aura\n",
            "ró-só-o\n",
            "sqiqte-asqiqte-sinte\n",
            "uluraa-auluraa-ultra\n",
            "dĩaz-adĩaz-da\n",
            "correptor-corretor-correto\n",
            "trtica-tática-troca\n",
            "ewpoderamento-aewpoderamento-ewpoderamento\n",
            "lifux-alifux-ligue\n",
            "îgato-gato-fato\n",
            "relógiuo-relógio-religião\n",
            "canelac-canela-janela\n",
            "anciosa-ansiosa-ansioso\n",
            "ansioa-ansiosa-antiga\n",
            "asterístico-aasterístico-asterístico\n",
            "gratuíto-agratuíto-gratuita\n",
            "entertido-aentertido-entendido\n",
            "ritimo-ritmo-ótimo\n",
            "tomare-tomar-tomar\n",
            "seje-seja-se\n",
            "provalecer-aprovalecer-prevalece\n",
            "esteje-esteja-este\n",
            "mindigo-amindigo-mendigos\n",
            "pertubar-perturbar-derrubar\n",
            "uhna-urna-uma\n",
            "mnoitor-monitor-motor\n",
            "linah-linha-minha\n",
            "inverãso-inverso-inverno\n",
            "esctuar-escutar-estar\n",
            "fleiz-feliz-fez\n",
            "Sugestões corretas: 41.54% de 195 palavras.\n",
            "Palavras desconhecidas: 8.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise dos corretores criados e conclusão"
      ],
      "metadata": {
        "id": "73qF2yTf5GiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possível perceber que a ocorrência de algumas palavras no corpus de treino influenciou a resposta do novo corretor para uma piora na performance. Por exemplo, a palavra errada 'fleiz' aparentemente foi um erro de digitação para 'feliz' com uma simples troca de letra. \n",
        "\n",
        "O corretor antigo sugeriu a palavra correta 'feliz'. \n",
        "O novo corretor, por sua vez, sugeriu 'fez', por ser uma palavra duas vezes distante de 'fleiz' que possui uma incidência maior no corpus de treino.\n",
        "\n",
        "Podemos testar com outras palavras:"
      ],
      "metadata": {
        "id": "-lDolurG4HgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# palavra com erro de digitação para 'lógica'\n",
        "palavra = 'lgica'\n",
        "print(corretor(palavra))\n",
        "print(novo_corretor(palavra))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH_qysNo4AVp",
        "outputId": "c92bda5e-5332-4890-afb3-973b92c7e67a"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lógica\n",
            "fica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparação dos corretores criados:"
      ],
      "metadata": {
        "id": "HNp9JU7O6SzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Resultado do primeiro corretor:')\n",
        "avaliador(lista_teste, vocabulario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e14oq5nI5Zw9",
        "outputId": "5f19231f-9fcc-433a-e5de-9e37328aa951"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado do primeiro corretor:\n",
            "Sugestões corretas: 76.92% de 195 palavras.\n",
            "Palavras desconhecidas: 8.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Resultado do segundo corretor:')\n",
        "novo_avaliador(lista_teste, vocabulario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-n7sOWz53Nn",
        "outputId": "b844eb31-2b18-4e97-cd43-bc0afed657bf"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado do segundo corretor:\n",
            "Sugestões corretas: 41.54% de 195 palavras.\n",
            "Palavras desconhecidas: 8.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apesar de ser uma função mais poderosa, o corretor antigo tem uma performance melhor para o presente corpus de treino e teste."
      ],
      "metadata": {
        "id": "rH6ztXVA5dq4"
      }
    }
  ]
}